# -*- coding: utf-8 -*-
"""web_scrapping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tp3qLGT0WOr3xftzhJmCjcwD7Q7Kvq82
"""

import requests
from bs4 import BeautifulSoup

url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue'

page  = requests.get(url)
print(page.text)

soup = BeautifulSoup(page.content, 'html.parser')
print(soup.prettify())



soup.find_all('table')[1]

table = soup.find('table', class_='wikitable sortable')

world_titles = table.find_all('th')

world_titles

world_table_titles = [title.text.strip() for title in world_titles]

print(world_table_titles)

import pandas as pd

df = pd.DataFrame(columns=world_table_titles)

df

column_data = table.find_all('tr')

for row in column_data[1:]:
    row_data = row.find_all('td')
    row_data = [data.text.strip() for data in row_data]
    length = len(df)
    df.loc[length] = row_data

df

df.to_csv('world_companies.csv')

import requests
from bs4 import BeautifulSoup

url = 'https://realpython.github.io/fake-jobs/'

page = requests.get(url)

soup = BeautifulSoup(page.content, 'html.parser')

results = soup.find(id='ResultsContainer')
print(results.prettify())

results_container = soup.find(id='ResultsContainer')

job_postings = results_container.find_all('div', class_='card-content')

job_postings[0]

print(type(job_postings))

import pandas as pd
frame = pd.DataFrame(columns=['title', 'company', 'location', 'date', 'apply', 'learn', 'image'])

frame

for job in job_postings:
    title_element = job.find('h2', class_='title')
    company_element = job.find('h3', class_='company')
    location_element = job.find('p', class_='location')
    date_element = job.find('time')
    apply_learn_elements = job.find_all('a', class_='card-footer-item')
    image_element = job.find('img')  # Assuming there's only one image per job

    title = title_element.text.strip() if title_element else "Title not found"
    company = company_element.text.strip() if company_element else "Company not found"
    location = location_element.text.strip() if location_element else "Location not found"
    date = date_element.text.strip() if date_element else "Date not found"

    if apply_learn_elements:
        apply = apply_learn_elements[0].get('href') if apply_learn_elements[0] else "Apply link not found"
        learn = apply_learn_elements[1].get('href') if len(apply_learn_elements) > 1 else "Learn link not found"
    else:
        apply = "Apply link not found"
        learn = "Learn link not found"

    image_src = image_element.get('src') if image_element else "Image not found"
    frame.loc[len(frame)] = [title, company, location, date, apply, learn, image_src]

    print("Title:", title)
    print("Company:", company)
    print("Location:", location)
    print("Date:", date)
    print("Apply:", apply)
    print("Learn:", learn)
    print("Image Source:", image_src)
    print("-" * 20)

frame

